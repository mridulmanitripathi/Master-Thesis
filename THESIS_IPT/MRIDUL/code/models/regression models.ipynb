{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fftpack import fftfreq\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "from math import pi\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import timeit\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b524f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924e6fb6",
   "metadata": {},
   "source": [
    "# Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers.csv')\n",
    "\n",
    "# converting avg peak value from mm to microns\n",
    "load_data['avg_peak'] = 1000*load_data['avg_peak']\n",
    "\n",
    "load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "(load_data['avg_peak']==0.1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eaafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some zero values to balance the dataset\n",
    "zero_index = []\n",
    "last = load_data.columns.get_loc(\"avg_peak\")\n",
    "for i in range(load_data.shape[0]):\n",
    "    if load_data.iloc[i,last]==0.1:\n",
    "        zero_index.append(i)\n",
    "        \n",
    "rand_zero_index = random.sample(zero_index,12000)\n",
    "load_data.drop(load_data.index[rand_zero_index], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nn = load_data['avg_peak']\n",
    "X_nn = load_data.drop(['avg_peak'], axis=1)\n",
    "\n",
    "# dividing data into training and test sets\n",
    "Y_nn = np.ravel(Y_nn)\n",
    "X_TrainVal, X_test, Y_TrainVal, Y_test = train_test_split(X_nn, Y_nn, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_TrainVal, Y_TrainVal, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input to neural network\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "scaler2 = StandardScaler().fit(Y_train)\n",
    "Y_train = scaler2.transform(Y_train)\n",
    "Y_val = scaler2.transform(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b50eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_nn.shape[1]\n",
    "\n",
    "# NN model\n",
    "model = Sequential()\n",
    "model.add(Dense(a, activation = 'relu', input_shape = (a,)))\n",
    "model.add(Dense(units = a//2, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = a//2, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(units = 1, activation = 'linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Compile model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.Huber(), \n",
    "              metrics=['mse', 'mae']\n",
    "             )\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train, epochs=200, batch_size=8000, validation_data=(X_val, Y_val), verbose=2)\n",
    "\n",
    "end_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training curves\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss magnitude')\n",
    "plt.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\loss_fnn_reg.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions using the model\n",
    "\n",
    "X_test_prediction = model.predict(X_test)\n",
    "Y_prediction = scaler2.inverse_transform(X_test_prediction)\n",
    "Y_prediction = Y_prediction.reshape((Y_prediction.shape[0],))\n",
    "Y_prediction[Y_prediction < 0] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ef42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance plots\n",
    "\n",
    "xlim = Y_test.shape[0]\n",
    "xaxis = np.arange(0,xlim,25)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax1.plot(xaxis, Y_test[0:xlim:25],'bo-',label = 'Real data',markerfacecolor='none')\n",
    "ax1.plot(xaxis, Y_prediction[0:xlim:25], 'rx--',label = 'Predicted data')\n",
    "ax2.plot(Y_prediction[5400:5450], 'rx--')\n",
    "ax2.plot(Y_test[5400:5450],'bo-',markerfacecolor='none')\n",
    "\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax1.set_xlabel('Data points (Sampled Test data)')\n",
    "ax2.set_xlabel('Data points (Subset of Test data)')\n",
    "#fig.legend(fontsize=18)\n",
    "\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\fnn_reg.png',bbox_inches='tight',dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(Y_test, Y_prediction)\n",
    "rmse = metrics.mean_squared_error(Y_test, Y_prediction, squared = False)\n",
    "\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Root mean square error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical features of test data\n",
    "\n",
    "df = pd.DataFrame(Y_test)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27735e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical features of predicted values\n",
    "\n",
    "df = pd.DataFrame(Y_prediction)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00eb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "\n",
    "df = pd.DataFrame(Y_test, columns=['True'])\n",
    "df['Predicted'] = Y_prediction.tolist()\n",
    "df = df.sort_values('True')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax2.plot(df['True'], abs(df['Predicted']-df['True']), label = 'Error = |Predicted Value - True Value|')\n",
    "\n",
    "ax1.plot(Y_prediction, 'rx',label = 'Predicted value')\n",
    "ax1.plot(Y_test,'bx',label = 'True value', markerfacecolor='none')\n",
    "\n",
    "ax2.set_ylabel('Absolute Error Values [$\\mu$m]')\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_xlabel('True Values (Test Data)')\n",
    "ax1.set_xlabel('Data points (Test data)')\n",
    "#fig.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\ffn_reg_error.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21495f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23f74b6c",
   "metadata": {},
   "source": [
    "# Residual neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity block\n",
    "def identity_block(input_tensor,units):\n",
    "    x = layers.Dense(units)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dense(units)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dense(units)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# dense block\n",
    "def dens_block(input_tensor,units):\n",
    "    x = layers.Dense(units)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dense(units)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dense(units)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    shortcut = layers.Dense(units)(input_tensor)\n",
    "    shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50Regression():\n",
    "    Res_input = layers.Input(shape=(load_data.shape[1]-1,))\n",
    "\n",
    "    width = 128\n",
    "\n",
    "    x = dens_block(Res_input,width)\n",
    "    x = identity_block(x,width)\n",
    "    x = identity_block(x,width)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(1, activation='softplus')(x)\n",
    "    model = models.Model(inputs=Res_input, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "# load data\n",
    "load_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers.csv')\n",
    "\n",
    "# converting avg peak value from mm to microns\n",
    "load_data['avg_peak'] = 1000*load_data['avg_peak']\n",
    "\n",
    "# dropping some zero values to balance the dataset\n",
    "zero_index = []\n",
    "last = load_data.columns.get_loc(\"avg_peak\")\n",
    "for i in range(load_data.shape[0]):\n",
    "    if load_data.iloc[i,last]==0.1:\n",
    "        zero_index.append(i)        \n",
    "rand_zero_index = random.sample(zero_index,12000)\n",
    "load_data.drop(load_data.index[rand_zero_index], axis=0, inplace=True)\n",
    "\n",
    "\n",
    "y = load_data['avg_peak']\n",
    "x = load_data.drop(['avg_peak'], axis=1)\n",
    "y = np.ravel(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# scaling the input to neural network\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_x.fit(x)\n",
    "xscale = scaler_x.transform(x)\n",
    "scaler_y.fit(y)\n",
    "yscale = scaler_y.transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size = 0.1, random_state = 3, shuffle = True)\n",
    "\n",
    "# Model\n",
    "model = ResNet50Regression()\n",
    "\n",
    "model.compile(loss= tf.keras.losses.Huber(),# 'mse'\n",
    "              optimizer='adam', \n",
    "              metrics=['mse','mae'])\n",
    "model.summary()\n",
    "\n",
    "#compute running time\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=1000, verbose=2, callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=2, mode='auto')], validation_split=0.1)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "\n",
    "# Save Model\n",
    "#model.save('OptimalModelDataSet2.h5')\n",
    "#plot_model(model, to_file='ResnetModel.png')\n",
    "#from keras.models import load_model\n",
    "#model.save('my_model.h5') \n",
    "#model = load_model('my_model.h5') \n",
    "\n",
    "# Model Predicting\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "print('The time cost: ')\n",
    "print(endtime - starttime)\n",
    "print('The test loss: ')\n",
    "print(mean_squared_error(yhat,y_test))\n",
    "\n",
    "#invert normalization\n",
    "yhat = scaler_y.inverse_transform(yhat) \n",
    "y_test = scaler_y.inverse_transform(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training curves\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss magnitude')\n",
    "plt.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\loss_resnet_reg.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94821a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance plots\n",
    "xlim = y_test.shape[0]\n",
    "xaxis = np.arange(0,xlim,25)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax1.plot(xaxis, y_test[0:xlim:25],'bo-',label = 'Real data',markerfacecolor='none')\n",
    "ax1.plot(xaxis, yhat[0:xlim:25], 'rx--',label = 'Predicted data')\n",
    "ax2.plot(yhat[1050:1100], 'rx--')\n",
    "ax2.plot(y_test[1050:1100],'bo-',markerfacecolor='none')\n",
    "\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax1.set_xlabel('Data points (Sampled Test data)')\n",
    "ax2.set_xlabel('Data points (Subset of Test data)')\n",
    "#ig.legend(fontsize=18)\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\resnet_reg.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "rmse = metrics.mean_squared_error(y_test, yhat, squared = False)\n",
    "\n",
    "\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Root mean square error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical features of predicted values\n",
    "\n",
    "df = pd.DataFrame(yhat)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d69d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "\n",
    "yhat = yhat.reshape(6676)\n",
    "df = pd.DataFrame(y_test, columns=['True'])\n",
    "df['Predicted'] = yhat.tolist()\n",
    "df = df.sort_values('True')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax2.plot(df['True'], abs(df['Predicted']-df['True']), label = 'Error = |Predicted Value - True Value|')\n",
    "\n",
    "ax1.plot(yhat, 'rx',label = 'Predicted value')\n",
    "ax1.plot(y_test,'bx',label = 'True value', markerfacecolor='none')\n",
    "\n",
    "ax2.set_ylabel('Absolute Error Values [$\\mu$m]')\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_xlabel('True Values (Test Data)')\n",
    "ax1.set_xlabel('Data points (Test data)')\n",
    "#fig.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\resnet_reg_error.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a62a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97a8c03d",
   "metadata": {},
   "source": [
    "# XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c46536",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers.csv')\n",
    "load_data['avg_peak'] = 1000*load_data['avg_peak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some zero values to balance the dataset\n",
    "zero_index = []\n",
    "last = load_data.columns.get_loc(\"avg_peak\")\n",
    "for i in range(load_data.shape[0]):\n",
    "    if load_data.iloc[i,last]==0.1:\n",
    "        zero_index.append(i)\n",
    "        \n",
    "rand_zero_index = random.sample(zero_index,12000)\n",
    "load_data.drop(load_data.index[rand_zero_index], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e051182",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nn = load_data['avg_peak']\n",
    "X_nn = load_data.drop(['avg_peak'], axis=1)\n",
    "\n",
    "# dividing data into training and test sets\n",
    "Y_nn = np.ravel(Y_nn)\n",
    "X_TrainVal, X_test, Y_TrainVal, Y_test = train_test_split(X_nn, Y_nn, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_TrainVal, Y_TrainVal, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4952d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input to neural network\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "scaler2 = StandardScaler().fit(Y_train)\n",
    "Y_train = scaler2.transform(Y_train)\n",
    "Y_val = scaler2.transform(Y_val)\n",
    "\n",
    "# scaling the input to neural network\n",
    "scaler3 = Normalizer().fit(X_train)\n",
    "X_train = scaler3.transform(X_train)\n",
    "X_test = scaler3.transform(X_test)\n",
    "X_val = scaler3.transform(X_val)\n",
    "\n",
    "scaler4 = MinMaxScaler().fit(Y_train)\n",
    "Y_train = scaler4.transform(Y_train)\n",
    "Y_val = scaler4.transform(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regressor\n",
    "model = XGBRegressor()\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "model.fit(X_train,Y_train, eval_set=[(X_val, Y_val)])\n",
    "end_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "\n",
    "X_test_prediction = model.predict(X_test)\n",
    "X_test_prediction = X_test_prediction.reshape(-1, 1)\n",
    "Y_prediction = scaler4.inverse_transform(X_test_prediction)\n",
    "Y_prediction = scaler2.inverse_transform(Y_prediction)\n",
    "Y_prediction[Y_prediction < 0] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965532ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance plots\n",
    "\n",
    "xlim = Y_test.shape[0]\n",
    "xaxis = np.arange(0,xlim,25)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax1.plot(xaxis, Y_test[0:xlim:25],'bo-',label = 'Real data',markerfacecolor='none')\n",
    "ax1.plot(xaxis, Y_prediction[0:xlim:25], 'rx--',label = 'Predicted data')\n",
    "ax2.plot(Y_prediction[4400:4450], 'rx--')\n",
    "ax2.plot(Y_test[4400:4450],'bo-',markerfacecolor='none')\n",
    "\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax1.set_xlabel('Data points (Sampled Test data)')\n",
    "ax2.set_xlabel('Data points (Subset of Test data)')\n",
    "#ig.legend(fontsize=18)\n",
    "\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\xgboost_reg.png',bbox_inches='tight',dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(Y_test, Y_prediction)\n",
    "rmse = metrics.mean_squared_error(Y_test, Y_prediction, squared = False)\n",
    "\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Root mean square error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f155d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical features of predicted values\n",
    "\n",
    "df = pd.DataFrame(Y_prediction)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "\n",
    "Y_prediction = Y_prediction.reshape(6676)\n",
    "df = pd.DataFrame(Y_test, columns=['True'])\n",
    "df['Predicted'] = Y_prediction.tolist()\n",
    "df = df.sort_values('True')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax2.plot(df['True'], abs(df['Predicted']-df['True']), label = 'Error = |Predicted Value - True Value|')\n",
    "\n",
    "ax1.plot(Y_prediction, 'rx',label = 'Predicted value')\n",
    "ax1.plot(Y_test,'bx',label = 'True value', markerfacecolor='none')\n",
    "\n",
    "ax2.set_ylabel('Absolute Error Values [$\\mu$m]')\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_xlabel('True Values (Test Data)')\n",
    "ax1.set_xlabel('Data points (Test data)')\n",
    "#fig.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\xgboost_reg_error.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299aa54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "293be821",
   "metadata": {},
   "source": [
    "# Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646517fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers.csv')\n",
    "load_data['avg_peak'] = 1000*load_data['avg_peak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d02866",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nn = load_data['avg_peak']\n",
    "X_nn = load_data.drop(['avg_peak'], axis=1)\n",
    "\n",
    "# dividing data into training and test sets\n",
    "Y_nn = np.ravel(Y_nn)\n",
    "X_TrainVal, X_test, Y_TrainVal, Y_test = train_test_split(X_nn, Y_nn, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_TrainVal, Y_TrainVal, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input to neural network\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "scaler2 = StandardScaler().fit(Y_train)\n",
    "Y_train = scaler2.transform(Y_train)\n",
    "Y_val = scaler2.transform(Y_val)\n",
    "\n",
    "# scaling the input to neural network\n",
    "scaler3 = Normalizer().fit(X_train)\n",
    "X_train = scaler3.transform(X_train)\n",
    "X_test = scaler3.transform(X_test)\n",
    "X_val = scaler3.transform(X_val)\n",
    "\n",
    "scaler4 = MinMaxScaler().fit(Y_train)\n",
    "Y_train = scaler4.transform(Y_train)\n",
    "Y_val = scaler4.transform(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "model.fit(X_train, Y_train)\n",
    "end_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "\n",
    "X_test_prediction = model.predict(X_test)\n",
    "X_test_prediction = X_test_prediction.reshape(-1, 1)\n",
    "Y_prediction = scaler4.inverse_transform(X_test_prediction)\n",
    "Y_prediction = scaler2.inverse_transform(Y_prediction)\n",
    "Y_prediction[Y_prediction < 0] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance plots\n",
    "\n",
    "xlim = 6686\n",
    "xaxis = np.arange(0,xlim,25)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax1.plot(xaxis, Y_test[0:xlim:25],'bo-',label = 'Real data',markerfacecolor='none')\n",
    "ax1.plot(xaxis, Y_prediction[0:xlim:25], 'rx--',label = 'Predicted data')\n",
    "ax2.plot(Y_prediction[200:250], 'rx--')\n",
    "ax2.plot(Y_test[200:250],'bo-',markerfacecolor='none')\n",
    "\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax1.set_xlabel('Data points (Sampled Test data)')\n",
    "ax2.set_xlabel('Data points (Subset of Test data)')\n",
    "#ig.legend(fontsize=18)\n",
    "\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\rf_reg.png',bbox_inches='tight',dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf491b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(Y_test, Y_prediction)\n",
    "rmse = metrics.mean_squared_error(Y_test, Y_prediction, squared = False)\n",
    "\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Root mean square error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical features of predicted values\n",
    "\n",
    "df = pd.DataFrame(Y_prediction)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d869bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "\n",
    "Y_prediction = Y_prediction.reshape(7876)\n",
    "df = pd.DataFrame(Y_test, columns=['True'])\n",
    "df['Predicted'] = Y_prediction.tolist()\n",
    "df = df.sort_values('True')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "ax2.plot(df['True'], abs(df['Predicted']-df['True']), label = 'Error = |Predicted Value - True Value|')\n",
    "\n",
    "ax1.plot(Y_prediction, 'rx',label = 'Predicted value')\n",
    "ax1.plot(Y_test,'bx',label = 'True value', markerfacecolor='none')\n",
    "\n",
    "ax2.set_ylabel('Absolute Error Values [$\\mu$m]')\n",
    "ax1.set_ylabel('Average peak value [$\\mu$m]')\n",
    "ax2.set_xlabel('True Values (Test Data)')\n",
    "ax1.set_xlabel('Data points (Test data)')\n",
    "#fig.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\rf_reg_error.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd59a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

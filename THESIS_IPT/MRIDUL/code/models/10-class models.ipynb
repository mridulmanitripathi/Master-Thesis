{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import timeit\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3849893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb03ab80",
   "metadata": {},
   "source": [
    "# Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5331c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers0_10.csv')\n",
    "load_data['avg_peak'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some zero values to balance the dataset\n",
    "zero_index = []\n",
    "last = load_data.columns.get_loc(\"avg_peak\")\n",
    "for i in range(load_data.shape[0]):\n",
    "    if load_data.iloc[i,last]==0:\n",
    "        zero_index.append(i)\n",
    "        \n",
    "rand_zero_index = random.sample(zero_index,12587)\n",
    "load_data.drop(load_data.index[rand_zero_index], axis=0, inplace=True)\n",
    "\n",
    "load_data['avg_peak'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the target features such that it starts with 0\n",
    "\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(1,0)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(2,1)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(3,2)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(4,3)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(5,4)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(6,5)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(7,6)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(8,7)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(9,8)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(10,9)\n",
    "load_data['avg_peak'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nn = load_data['avg_peak']\n",
    "Y_nn = np.ravel(Y_nn)\n",
    "\n",
    "# label encoding of target variable (one hot encoding)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_nn)\n",
    "\n",
    "# dividing data into training and test sets\n",
    "X_nn = load_data.drop(['avg_peak'], axis=1)\n",
    "\n",
    "X_TrainVal, X_test, Y_TrainVal, Y_test = train_test_split(X_nn, Y_nn, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_TrainVal, Y_TrainVal, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input to neural network\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# scaling the input to neural network\n",
    "scaler2 = Normalizer().fit(X_train)\n",
    "X_train = scaler2.transform(X_train)\n",
    "X_test = scaler2.transform(X_test)\n",
    "X_val = scaler2.transform(X_val)\n",
    "\n",
    "# one hot encoding of target variable\n",
    "Y_train = encoder.transform(Y_train)\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = encoder.transform(Y_val)\n",
    "Y_val = to_categorical(Y_val)\n",
    "Y_test = encoder.transform(Y_test)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_nn.shape[1]\n",
    "\n",
    "# neural network model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(a//2, activation = 'relu', input_shape = (a,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units = a//2, activation = 'relu'))\n",
    "model.add(Dense(units = a//2, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics='accuracy'\n",
    "             )\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train, batch_size=5000, epochs=300, validation_data=(X_val,Y_val), verbose=1)#, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training curves\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64333e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluting model performance\n",
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ec604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "Y_prediction = model.predict(X_test)\n",
    "Y_prediction = Y_prediction.argmax(axis=1)\n",
    "Y_test = Y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "x_axis_labels = [1,2,3,4,5,6,7,8,9,10] # labels for x-axis\n",
    "y_axis_labels = [1,2,3,4,5,6,7,8,9,10] # labels for y-axis\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(8,4)})\n",
    "sn.heatmap(confusion_matrix(Y_test, Y_prediction), \n",
    "           annot=True,fmt='g', cmap='Greens', cbar=False,\n",
    "          xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\nn_10.png',bbox_inches='tight',dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a08079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37c61a92",
   "metadata": {},
   "source": [
    "# XGBoost classifier, Random forest classifier, Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers0_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some zero values to balance the dataset\n",
    "zero_index = []\n",
    "last = load_data.columns.get_loc(\"avg_peak\")\n",
    "for i in range(load_data.shape[0]):\n",
    "    if load_data.iloc[i,last]==0:\n",
    "        zero_index.append(i)\n",
    "        \n",
    "rand_zero_index = random.sample(zero_index,12000)\n",
    "load_data.drop(load_data.index[rand_zero_index], axis=0, inplace=True)\n",
    "\n",
    "load_data['avg_peak'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca121339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the target features such that it starts with 0\n",
    "\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(1,0)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(2,1)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(3,2)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(4,3)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(5,4)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(6,5)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(7,6)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(8,7)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(9,8)\n",
    "load_data['avg_peak'] = load_data['avg_peak'].replace(10,9)\n",
    "load_data['avg_peak'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nn = load_data['avg_peak']\n",
    "X_nn = load_data.drop(['avg_peak'], axis=1)\n",
    "\n",
    "# dividing data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_nn, Y_nn, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 3,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "\n",
    "# scaling the input to neural network\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af98eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the classifier\n",
    "\n",
    "# i = 0 : XGBoost\n",
    "# i = 1 : Random forest\n",
    "# i = 2 : SVM\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de847e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if i==0:\n",
    "    # XGBoost classifier\n",
    "    model = XGBClassifier(objective='multi:softmax')\n",
    "    start_time = timeit.default_timer()\n",
    "    model.fit(X_train,Y_train)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(end_time - start_time)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "if i==1:\n",
    "    # Random forest classifier\n",
    "    model = RandomForestClassifier(class_weight='balanced_subsample')\n",
    "    model.fit(X_train,Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "if i==2:\n",
    "    # SVM\n",
    "    clf = svm.SVC(kernel='rbf', gamma=0.1, class_weight='balanced') # set Kernel: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7396ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
    "\n",
    "\n",
    "print('classification report')\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97215f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "x_axis_labels = [1,2,3,4,5,6,7,8,9,10] # labels for x-axis\n",
    "y_axis_labels = [1,2,3,4,5,6,7,8,9,10] # labels for y-axis\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(8,4)})\n",
    "sn.heatmap(confusion_matrix(Y_test, y_pred), \n",
    "           annot=True,fmt='g', cmap='Greens', cbar=False,\n",
    "          xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\svm_10.png',bbox_inches='tight',dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

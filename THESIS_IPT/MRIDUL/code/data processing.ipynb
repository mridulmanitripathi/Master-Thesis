{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1108306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import peakutils\n",
    "import scipy\n",
    "from scipy import fft\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fftpack import fftfreq\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import OneClassSVM\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "from math import pi\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import warnings\n",
    "from time import process_time\n",
    "from matplotlib import cm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "\n",
    "# sampling frequencies of the sensors used for data acquistion\n",
    "sampling_vibration = 50000\n",
    "sampling_acoustic = 1000\n",
    "\n",
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154191f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9ea080",
   "metadata": {},
   "source": [
    "# START of the data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c454b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "121204ce",
   "metadata": {},
   "source": [
    "### Data processing for aircut / milling data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63658f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling the vibration data as aircut (0) and milling (1) for trials 2,9,12,18\n",
    "\n",
    "# reading the vibration data\n",
    "data = h5py.File(r'M:\\THESIS_IPT\\MRIDUL\\Versuche\\vibration_data1\\18.h5', 'r')\n",
    "Vibration_X=data['acq_0_MCI42__AnalogInputs_AI1'][:] / 0.0967              #Coefficients depends on the sensor, converts the digital signal values to a physical unit \n",
    "Vibration_Y=data['acq_0_MCI42__AnalogInputs_AI2'][:] / 0.0968\n",
    "Vibration_Z=data['acq_0_MCI42__AnalogInputs_AI3'][:] / 0.0947\n",
    "\n",
    "# combining the vibrations in all directions into one list\n",
    "combined_vibration = []\n",
    "combined_vibration.append(Vibration_X)\n",
    "combined_vibration.append(Vibration_Y)\n",
    "combined_vibration.append(Vibration_Z)\n",
    "\n",
    "# determining start and end of the milling operations for a milling trial\n",
    "ind_start, ind_end = functions.milling_ind(combined_vibration[0], int_size = 1000, cutoff = 1)\n",
    "# generating labels\n",
    "air_mill_data = functions.air_mill_classify(combined_vibration, ind_start, ind_end)\n",
    "\n",
    "plt.plot(air_mill_data['aircut0'])\n",
    "\n",
    "#air_mill_data.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\18airmill.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\18airmill.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a rolling window of size 20 ms (1000 data points)\n",
    "\n",
    "air_mill_data = pd.DataFrame()\n",
    "\n",
    "# window size\n",
    "window_length = 1000\n",
    "lim = data.shape[0]//window_length\n",
    "window_half = window_length//2\n",
    "\n",
    "for i in range(2*lim):\n",
    "    # overlapping rolling windows\n",
    "    temp = data.iloc[i*window_half:i*window_half+window_length].copy()\n",
    "    \n",
    "    # computing maximum acceleration value in each window\n",
    "    max_x = temp['vibration_x'].max()\n",
    "    max_y = temp['vibration_y'].max()\n",
    "    max_z = temp['vibration_z'].max()\n",
    "    \n",
    "    # generating labels \n",
    "    # label = 1 if more than 50% data in the window belong to the milling class\n",
    "    # label = 0 if more than 50% data in the window belong to the aircut class\n",
    "    num_one = (temp['aircut0']==1).sum()\n",
    "    if num_one>window_half:\n",
    "        aircut = 1\n",
    "    else:\n",
    "        aircut = 0\n",
    "        \n",
    "    data_entries = [[max_x, max_y, max_z, aircut]]\n",
    "    air_mill_data=air_mill_data.append(data_entries, ignore_index=True)\n",
    "        \n",
    "\n",
    "# Dataframe storing maximum acceleration values of the windows along with label (aircut/milling)        \n",
    "air_mill_data.columns = [['max_x', 'max_y', 'max_z', 'aircut']] \n",
    "\n",
    "plt.plot(air_mill_data['aircut'])\n",
    "\n",
    "#air_mill_data.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\taking window\\20ms\\18airmill.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging datasets to obtain training data\n",
    "\n",
    "data1=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\taking window\\20ms\\02airmill.csv')\n",
    "data2=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\taking window\\20ms\\09airmill.csv')\n",
    "data3=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\taking window\\20ms\\12airmill.csv')\n",
    "data4=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\air_mill\\taking window\\20ms\\18airmill.csv')\n",
    "\n",
    "data2 = data2.append(data1, ignore_index=True)\n",
    "data4 = data4.append(data3, ignore_index=True)\n",
    "data4 = data4.append(data2, ignore_index=True)\n",
    "\n",
    "#data4.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\model data\\airmill.csv',index=False)\n",
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e403908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9018f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9a9372e",
   "metadata": {},
   "source": [
    "### Data processing for surface profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c597dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually merging the vibration data with the surface data for all trials\n",
    "\n",
    "VibationData = h5py.File(r'M:\\THESIS_IPT\\MRIDUL\\Versuche\\vibration_data1\\06.h5', 'r')\n",
    "filename_surface1 = r'M:\\THESIS_IPT\\MRIDUL\\surface_data_WZL\\layer1\\Part06_Line1.txt'\n",
    "filename_surface2 = r'M:\\THESIS_IPT\\MRIDUL\\surface_data_WZL\\layer1\\Part06_Line2.txt'\n",
    "filename_surface3 = r'M:\\THESIS_IPT\\MRIDUL\\surface_data_WZL\\layer1\\Part06_Line3.txt'\n",
    "filename_surface4 = r'M:\\THESIS_IPT\\MRIDUL\\surface_data_WZL\\layer1\\Part06_Line4.txt'\n",
    "filename_surface5 = r'M:\\THESIS_IPT\\MRIDUL\\surface_data_WZL\\layer1\\Part06_Line5.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,surf_profile1 = functions.extract_surface(filename_surface1)\n",
    "_,surf_profile2 = functions.extract_surface(filename_surface2)\n",
    "_,surf_profile3 = functions.extract_surface(filename_surface3)\n",
    "_,surf_profile4 = functions.extract_surface(filename_surface4)\n",
    "_,surf_profile5 = functions.extract_surface(filename_surface5)\n",
    "\n",
    "surf_combined = []\n",
    "surf_combined.append(surf_profile1)\n",
    "surf_combined.append(surf_profile2)\n",
    "surf_combined.append(surf_profile3)\n",
    "surf_combined.append(surf_profile4)\n",
    "surf_combined.append(surf_profile5)\n",
    "\n",
    "Vibration_X=VibationData['acq_0_MCI42__AnalogInputs_AI1'][:] / 0.0967 \n",
    "Vibration_Y=VibationData['acq_0_MCI42__AnalogInputs_AI2'][:] / 0.0968\n",
    "Vibration_Z=VibationData['acq_0_MCI42__AnalogInputs_AI3'][:] / 0.0947\n",
    "\n",
    "vibration_combined = []\n",
    "vibration_combined.append(Vibration_X)\n",
    "vibration_combined.append(Vibration_Y)\n",
    "vibration_combined.append(Vibration_Z)\n",
    "\n",
    "ind_start, ind_end = functions.milling_ind(vibration_combined[0], int_size = 1000, cutoff = 1)\n",
    "\n",
    "merged_data = functions.merge_vibration_surface(vibration_combined, surf_combined, ind_start, ind_end)\n",
    "\n",
    "#merged_data.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\merged_surface\\06merged1.csv',index=False)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ed234",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = list(np.linspace(0, Vibration_X.shape[0], 11, endpoint = True))  #Creates 11 equidistant ticks in range of Vibration signal (beginning to end)\n",
    "xlabels = tuple([int(i / 50000) for i in xticks]) \n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(16,4))\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Acceleration [$m/s^2$]')\n",
    "ax1.plot(merged_data['vibration_x'], label='Vibration X')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Surface Profile [mm]')\n",
    "ax2.plot(merged_data['surface_roughness'], color='orange',label='Surface Profile')\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=0, fontsize=16) \n",
    "\n",
    "plt.xticks(xticks,xlabels)\n",
    "plt.title('Vibration X and Surface Profiles')\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\1_6vibx_surface.png',bbox_inches='tight', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79fadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14ccf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d51a4047",
   "metadata": {},
   "source": [
    "### Adding features for vibration data (for all milling trials at once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cb4fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding vibration features (time domain + frequency domain)\n",
    "\n",
    "# location of files containing vibration data merged with surface data\n",
    "file_loc = r'M:\\THESIS_IPT\\MRIDUL\\merged_surface'\n",
    "# location for storing files containing the vibration features and the target variable (mean peak value)\n",
    "location = r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\merged_vibration_only'\n",
    "\n",
    "for file in os.listdir(file_loc):\n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    # reading all csv files one by one\n",
    "    if filename.endswith('.csv'):\n",
    "        print(os.path.join(file_loc, filename))\n",
    "        path_ = os.path.join(file_loc, filename)\n",
    "        merge_data=pd.read_csv(path_)\n",
    "        features_data = pd.DataFrame()\n",
    "        \n",
    "        # window size\n",
    "        window_length = 1000\n",
    "        window_half = window_length//2\n",
    "        lim = merge_data.shape[0]//window_length\n",
    "        \n",
    "        # overlapping rolling windows\n",
    "        for i in range(2*lim):\n",
    "            temp = merge_data.iloc[i*window_half:i*window_half+window_length].copy()\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            \n",
    "            # adding the computed features\n",
    "            features = functions.add_features(temp, sampling_vibration, win=window_length-1, segment_length=window_length) # keep window size high and 1000//win should not equal to 0\n",
    "            features_data=features_data.append(features, ignore_index=True)\n",
    "        \n",
    "        features_data = features_data.fillna(0.0001)\n",
    "        \n",
    "        # column names for added features\n",
    "        features_data.columns = [['rms_x', 'rms_y', 'rms_z', \n",
    "                                  'kurt_x', 'kurt_y', 'kurt_z',\n",
    "                                  'skew_x', 'skew_y', 'skew_z',\n",
    "                                  'mean_x', 'mean_y', 'mean_z',\n",
    "                                  'std_x', 'std_y', 'std_z',\n",
    "                                  'peak_x', 'peak_y', 'peak_z',\n",
    "                                  'crest_x', 'crest_y', 'crest_z',\n",
    "                                  'clear_x', 'clear_y', 'clear_z',\n",
    "                                  'shape_x', 'shape_y', 'shape_z',\n",
    "                                  'impulse_x', 'impulse_y', 'impulse_z',\n",
    "                                  'msf_x', 'msf_y', 'msf_z',\n",
    "                                  'osac_x', 'osac_y', 'osac_z',\n",
    "                                  'fc_x', 'fc_y', 'fc_z',\n",
    "                                  'sf_x', 'sf_y', 'sf_z',\n",
    "                                  'avg_peak', \n",
    "                                  'frac_dim_x', 'frac_dim_y', 'frac_dim_z',\n",
    "                                  'fifth_x', 'fifth_y', 'fifth_z',\n",
    "                                  'sixth_x', 'sixth_y', 'sixth_z',\n",
    "                                  'freq_x_0_5000', 'freq_x_5000_10000', 'freq_x_10000_15000', 'freq_x_15000_20000', 'freq_x_20000_25000',\n",
    "                                  'freq_y_0_5000', 'freq_y_5000_10000', 'freq_y_10000_15000', 'freq_y_15000_20000', 'freq_y_20000_25000',\n",
    "                                  'freq_z_0_5000', 'freq_z_5000_10000', 'freq_z_10000_15000', 'freq_z_15000_20000', 'freq_z_20000_25000']]         \n",
    "        \n",
    "        \n",
    "        # extracting name of the file for storing\n",
    "        name = os.path.splitext(file)[0]\n",
    "        \n",
    "        #features_data.to_csv(location + '//' + name + 'vibration' + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fd6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13a5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3382b68f",
   "metadata": {},
   "source": [
    "### Adding features for acoustic data (for all milling trials at once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding acoustic features (frequency domain)\n",
    "\n",
    "# directories\n",
    "\n",
    "# location of files containing features of vibration data \n",
    "file_loc = r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\merged_vibration_only'\n",
    "mer_vib_data=[]\n",
    "for file in os.listdir(file_loc):\n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    if filename.endswith('.csv'):\n",
    "        path_ = os.path.join(file_loc, filename)\n",
    "        mer_vib_data.append(path_)\n",
    "\n",
    "# location of files containing features of sensor data \n",
    "file_loc = r'M:\\THESIS_IPT\\MRIDUL\\Versuche\\vibration_data_mixed'\n",
    "sens_data=[]\n",
    "for file in os.listdir(file_loc):\n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    if filename.endswith('.h5'):\n",
    "        path_ = os.path.join(file_loc, filename)\n",
    "        sens_data.append(path_)\n",
    "\n",
    "# printing name of the directories for verifying the order of files being read\n",
    "for i in range(len(mer_vib_data)):\n",
    "    print(mer_vib_data[i])\n",
    "    print(sens_data[i])\n",
    "    name = os.path.splitext(mer_vib_data[i])[0]\n",
    "    \n",
    "    # extracting name of the file for storing\n",
    "    print(len(name))\n",
    "    print(name[84:])    # change this if the directory is changed\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f79c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding acoustic features (frequency domain)\n",
    "\n",
    "# location of files for storing the dataframe containing features of vibration data and acoustic data\n",
    "location = r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\merged_vibration_ae' \n",
    "\n",
    "for j in range(len(mer_vib_data)):\n",
    "    \n",
    "    # name of the file containing the vibration features\n",
    "    print(mer_vib_data[j])\n",
    "    # name of the file containing sensor data\n",
    "    print(sens_data[j])\n",
    "    print('\\n')\n",
    "    \n",
    "    merge_features_data=pd.read_csv(mer_vib_data[j])\n",
    "    \n",
    "    # reading the acoustic data\n",
    "    data = h5py.File(sens_data[j], 'r')\n",
    "    AE_temp=data['acq_1_MCI42__AnalogInputsHS_RawHS1[0]'][:]\n",
    "    \n",
    "    features_data = pd.DataFrame()\n",
    "\n",
    "    # frequency is recorded from 0 kHz to 500 kHz with a uniform interval of 5 kHz\n",
    "    freq = np.arange(0,500,5)\n",
    "\n",
    "    # window length\n",
    "    # sampling rate of AE sensor = 1000 Hz. In 20 ms, it with record 20 STFT windows (i.e 20*100 = 2000 datapoints) \n",
    "    window_length = 2*1000\n",
    "    window_half = window_length//2\n",
    "    lim = AE_temp.shape[0]//window_length\n",
    "    \n",
    "    # overlapping rolling window\n",
    "    for i in range(2*lim):\n",
    "        temp = AE_temp[i*window_half:i*window_half+window_length]\n",
    "        \n",
    "        # computing STFT of the acoustic data\n",
    "        fft_ae = functions.fftAE(signal = temp, sample_rate = sampling_acoustic)\n",
    "        # computing mean of amplitudes of 20 STFT windows\n",
    "        mean_fft_ae = np.mean(fft_ae, axis=0)\n",
    "        mag = mean_fft_ae\n",
    "        \n",
    "        # adding generated features\n",
    "        features = functions.add_AEfeatures(freq,mag)\n",
    "        features_data=features_data.append(features, ignore_index=True)\n",
    "    \n",
    "    # column names for the added features\n",
    "    features_data.columns = ['AE_msf','AE_osac', 'AE_fc', 'AE_sf',\n",
    "                             'freqAE_0_100', 'freqAE_100_200', 'freqAE_200_300', 'freqAE_300_400', 'freqAE_400_500']\n",
    "    \n",
    "    # merging the dataframe of vibration features with the dataframe with acoustic features\n",
    "    new = pd.concat([merge_features_data, features_data], axis=1)\n",
    "    \n",
    "    # extracting name for storing the file\n",
    "    temp = os.path.splitext(mer_vib_data[j])[0]\n",
    "    name = temp[84:]\n",
    "    \n",
    "    #new.to_csv(location + '//' + name + 'AE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef576ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ffbcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61924265",
   "metadata": {},
   "source": [
    "### Combining all files containing the features from the milling trials into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.DataFrame()\n",
    "\n",
    "# location of files for storing the dataframe containing features of vibration data and acoustic data\n",
    "file_loc = 'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\merged_vibration_ae'\n",
    "for file in os.listdir(file_loc):\n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    # reading all csv files\n",
    "    if filename.endswith('.csv'):\n",
    "        loc = os.path.join(file_loc, filename)\n",
    "        temp = pd.read_csv(str(loc))\n",
    "        # merging all files into one (adding dataframes one below another)\n",
    "        data_all = data_all.append(temp, ignore_index=True)\n",
    "\n",
    "#data_all.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\combined_merged_featuresALL.csv',index=False)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e4984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42062b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484758d6",
   "metadata": {},
   "source": [
    "### Removing undesired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1fb413",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\combined_merged_featuresALL.csv')\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(combined_data['avg_peak'])\n",
    "plt.show()\n",
    "\n",
    "# dropping the start and end of the milling data that are characterised by large magnitudes of average peak value\n",
    "combined_data.drop(combined_data[combined_data['avg_peak'] > 0.1].index, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(combined_data['avg_peak'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping random air data to have balanced amount of aircut and milling data for training\n",
    "\n",
    "air_index = []\n",
    "# selecting aircut data based on the value of target variable\n",
    "col_num = combined_data.columns.get_loc(\"avg_peak\")\n",
    "\n",
    "# storing the indices of the aircut data\n",
    "for i in range(combined_data.shape[0]):\n",
    "    if combined_data.iloc[i,col_num]==0.0001:\n",
    "        air_index.append(i)\n",
    "        \n",
    "print('number of aircut datapoints:',len(air_index))\n",
    "\n",
    "mill_points = combined_data.shape[0] - len(air_index)\n",
    "print('number of milling datapoints:',mill_points)\n",
    "\n",
    "diff_points = len(air_index) - mill_points\n",
    "points_to_drop = mill_points + diff_points//2\n",
    "print('number of data points to be dropped from the aircut data:',points_to_drop)\n",
    "\n",
    "# randomly selecting the indices of aircut data for deletion\n",
    "rand_air_index = random.sample(air_index,points_to_drop)\n",
    "\n",
    "# dropping the aircut data to reduce its influence while training the ML model\n",
    "combined_data.drop(combined_data.index[rand_air_index], axis=0, inplace=True)\n",
    "\n",
    "# storing the modified dataset\n",
    "#combined_data.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e9345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ce7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b40526",
   "metadata": {},
   "source": [
    "### Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb3819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL.csv')\n",
    "\n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.plot(combined_data['rms_x'])\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Acceleration [$m/s^2$]')\n",
    "plt.title('Root Mean Square values BEFORE Outliers Removal')\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\outlierBEFORE_1_6_RMS.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "p, (ax1, ax2) = plt.subplots(1,2,figsize=(16,9))\n",
    "p.suptitle(\"Data of all Milling Trials Combined: Before and After Outliers Removal\")\n",
    "\n",
    "combined_data.boxplot('rms_x', ax=ax1)\n",
    "ax1.set_xlabel('Before Outliers Removal')\n",
    "ax1.set_ylim(-1,15)\n",
    "ax1.set_ylabel('Acceleration [$m/s^2$]')\n",
    "\n",
    "Q1 = combined_data['rms_x'].quantile(0.25)\n",
    "Q3 = combined_data['rms_x'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_range1 = Q3 + 1.5*IQR\n",
    "outlier_range2 = Q1 - 1.5*IQR\n",
    "combined_data.drop(combined_data[combined_data['rms_x'] > outlier_range1].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['rms_x'] < outlier_range2].index, inplace=True)\n",
    "\n",
    "combined_data.boxplot('rms_x', ax=ax2)\n",
    "ax2.set_xlabel('After Outliers Removal')\n",
    "ax2.set_ylim(-1,15)\n",
    "ax2.set_ylabel('Acceleration [$m/s^2$]')\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\outliers_1_6_RMS.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.plot(combined_data['rms_x'], label='RMS values')\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Acceleration [$m/s^2$]')\n",
    "plt.title('Root Mean Square values AFTER Outliers Removal')\n",
    "plt.legend()\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\outlierAFTER_1_6_RMS.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "combined_data=pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL.csv')\n",
    "combined_data.drop(combined_data[combined_data['rms_x'] > 10].index, inplace=True)\n",
    "\n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.plot(combined_data['rms_x'])\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Acceleration [$m/s^2$]')\n",
    "plt.title('Root Mean Square values AFTER Outliers Removal')\n",
    "#plt.savefig(r'M:\\THESIS_IPT\\REPORT\\images\\outlierAFTER2.0_1_6_RMS.png',bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d0983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plots for all features for visual identification of outliers\n",
    "for i in range(combined_data.shape[1]):\n",
    "    print(combined_data.columns[i])\n",
    "    plt.plot(combined_data.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outlier: dropping the data points based on their values\n",
    "\n",
    "combined_data.drop(combined_data[combined_data['rms_x'] > 10].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['rms_y'] > 20].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['kurt_x'] > 75000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['kurt_y'] > 40000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['kurt_z'] > 50000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['skew_x'] > 2500].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['skew_x'] < -2500].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['skew_y'] < -1100].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['skew_z'] < -2000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['mean_x'] > 1].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['mean_x'] < -1].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['mean_y'] > 1].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['mean_y'] < -1].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['crest_x'] > 13].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['crest_y'] > 12].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['crest_z'] > 15].index, inplace=True)\n",
    "#combined_data.drop(combined_data[combined_data['clear_x'] > 15].index, inplace=True)\n",
    "#combined_data.drop(combined_data[combined_data['clear_y'] > 15].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['clear_z'] > 20].index, inplace=True)\n",
    "#combined_data.drop(combined_data[combined_data['impulse_x'] > 20].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['impulse_y'] > 20].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['impulse_z'] > 20].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['fifth_x'] < -1000000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['fifth_x'] > 1000000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['fifth_y'] < -400000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['fifth_z'] < -500000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['sixth_x'] > 5000000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['sixth_y'] > 2000000].index, inplace=True)\n",
    "combined_data.drop(combined_data[combined_data['sixth_z'] > 10000000].index, inplace=True)\n",
    "\n",
    "\n",
    "#combined_data.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\emre_stft_vib\\Combined_final_ALL_noOutliers.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b874ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db822f2",
   "metadata": {},
   "source": [
    "### Tranforming the dataset to classification data (with multiple classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f67ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers.csv')\n",
    "\n",
    "# number of classes\n",
    "num_classes = 10\n",
    "final_data = functions.class_transform(num_classes, combined_data)\n",
    "\n",
    "#final_data.to_csv(r'M:\\THESIS_IPT\\MRIDUL\\data_overlapping_windows\\points1000_20ms\\Combined_final_ALL_noOutliers0_10.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb701f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
